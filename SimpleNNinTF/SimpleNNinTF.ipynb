{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple NN in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.1.0\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\"\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, x, y):\n",
    "      super(Model, self).__init__()\n",
    "\n",
    "      self.x_input = tf.constant(x, dtype=tf.float64)\n",
    "      self.y_input = tf.constant(y, dtype=tf.float64)\n",
    "\n",
    "      # Layer 1 - hidden layer\n",
    "      self.W1 = tf.Variable(tf.random.uniform([2,2], minval=0., maxval=1., dtype=tf.float64), trainable = True, name='W1')\n",
    "      self.b1 = tf.Variable(tf.random.uniform([2], minval=0., maxval=1., dtype=tf.float64), trainable = True, name='b1')\n",
    "\n",
    "      #Layer 2 - output layer \n",
    "      self.W2 = tf.Variable(tf.random.uniform([2,1], minval=0., maxval=1., dtype=tf.float64), trainable = True, name='W2')\n",
    "      self.b2 = tf.Variable(tf.random.uniform([1], minval=0., maxval=1., dtype=tf.float64), trainable = True, name='b2')\n",
    "\n",
    "    def call(self, inputs):\n",
    "      inputs = tf.constant(inputs, dtype=tf.float64)\n",
    "\n",
    "      in_neurons_hidden_layer = tf.add(tf.linalg.matmul(inputs, self.W1),self.b1) #x*W+b\n",
    "      out_neurons_hidden_layer = tf.sigmoid(in_neurons_hidden_layer)\n",
    "\n",
    "      in_neurons_output_layer = tf.add(tf.linalg.matmul(out_neurons_hidden_layer, self.W2),self.b2) #x*W+b\n",
    "      out_neurons_output_layer = tf.sigmoid(in_neurons_output_layer)\n",
    "\n",
    "      return out_neurons_output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input1</th>\n",
       "      <th>input2</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input1  input2  output\n",
       "0     0.0     0.0     0.0\n",
       "1     1.0     1.0     0.0\n",
       "2     0.0     1.0     1.0\n",
       "3     1.0     0.0     1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#The data\n",
    "x = np.array([[0.,0.],[1.,1.],[0.,1.],[1.,0.]])\n",
    "y = np.array([0.,0.,1.,1.])\n",
    "\n",
    "pd.DataFrame({\n",
    "    'input1':np.vstack(x).T[0],\n",
    "    'input2': np.vstack(x).T[1],\n",
    "    'output':y\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "summary_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "model = Model(x, y)\n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.9)\n",
    "\n",
    "def loss(outputs_model, targets):\n",
    "  error = tf.math.subtract(targets,outputs_model)\n",
    "  return tf.reduce_sum(tf.square(error))\n",
    "\n",
    "def get_gradient(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model(inputs), targets)\n",
    "  return tape.gradient(loss_value, [model.W1, model.b1, model.W2, model.b2])\n",
    "\n",
    "def run_network(inputs, targets, epochs):\n",
    "  for i in range(epochs):\n",
    "    grads=get_gradient(model, inputs, targets)\n",
    "    optimizer.apply_gradients(zip(grads, [model.W1, model.b1, model.W2, model.b2]))\n",
    "    loss_epoch = loss(model(inputs), model.y_input)\n",
    "    with summary_writer.as_default():\n",
    "      tf.summary.scalar('loss', loss_epoch, step=i)\n",
    "    if i % 100 == 0 :\n",
    "      print(f\"Loss at the epoch {i}: {loss_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at the epoch 0: 5.454746179717792\n",
      "Loss at the epoch 100: 4.002198551313024\n"
     ]
    }
   ],
   "source": [
    "run_network(x,y,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-45ab6072f68af400\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-45ab6072f68af400\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baiduenv",
   "language": "python",
   "name": "baiduenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
